
services:
  broker:
    image: confluentinc/confluent-local:7.4.1
    hostname: broker
    container_name: broker
    ports:
      - "8082:8082"
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://localhost:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@localhost:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://localhost:29092,CONTROLLER://localhost:29093,PLAINTEXT_HOST://0.0.0.0:9092'
    network_mode: host

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - 9999:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: true
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: localhost:29092
    network_mode: host


  postgres:
    image: "postgres:17"
    ports:
      - 5432:5432
    environment:
      POSTGRES_USER: username
      POSTGRES_PASSWORD: password
      POSTGRES_DB: postgres
    network_mode: host

  # thrift-server:
  #   build: .
  #   container_name: thrift-server
  #   hostname: localhost
  #   command: | 
  #     bash -c "/opt/spark/sbin/start-thriftserver.sh \\
  #             --master spark://localhost:7077 \\
  #             --conf spark.sql.warehouse.dir=/tmp/spark-warehouse \\
  #             --hiveconf hive.server2.thrift.port=10000 \\
  #             --conf spark.cores.max=1 \\
  #             --conf spark.executor.memory=1g \\
  #             --conf spark.executor.instances=1 \\
  #             --conf spark.dynamicAllocation.enabled=false && \\
  #             tail -f '/opt/spark/logs/spark--org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-1-localhost.out' "
  #   stdin_open: true
  #   tty: true
  #   network_mode: host

  spark-master:
    build: .
    hostname: localhost
    container_name: spark-master
    # command: | 
    #   bash -c "/opt/spark/sbin/start-master.sh -p 7077 &&  \ 
    #           /opt/spark/sbin/start-thriftserver.sh --master spark://localhost:7077 --conf spark.sql.warehouse.dir=/tmp/spark-warehouse --hiveconf hive.server2.thrift.port=10000 && \
    #           tail -f '/opt/spark/logs/spark--org.apache.spark.deploy.master.Master-1-localhost.out' '/opt/spark/logs/spark--org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-1-localhost.out' "
    command: | 
      bash -c "/opt/spark/sbin/start-master.sh -p 7077 &&  \ 
              tail -f '/opt/spark/logs/spark--org.apache.spark.deploy.master.Master-1-localhost.out'"
    stdin_open: true 
    tty: true
    environment:
      SPARK_MASTER_HOST: localhost
      SPARK_MASTER_WEBUI_PORT: 8000

    network_mode: host
    ports:
      - "9090:8080"
      - "7077:7077"
    volumes:
      - ./spark_jobs:/opt/spark/apps

  spark-worker:
    build: .
    hostname: localhost
    command: | 
      bash -c "/opt/spark/sbin/start-worker.sh spark://localhost:7077 && tail -f '/opt/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-localhost.out'"
    stdin_open: true
    tty: true
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    volumes:
      - ./spark_jobs:/opt/spark/apps
    network_mode: host
    scale: 1
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_HOST: localhost
      SPARK_WORKER_PORT: 8081
      SPARK_MASTER_URL: spark://localhost:7077

  # cassandra_db:
  #   image: cassandra:latest
  #   container_name: cassandra
  #   hostname: cassandra
  #   ports:
  #     - "9042:9042"
  #   environment:
  #     - MAX_HEAP_SIZE=512M
  #     - HEAP_NEWSIZE=100M
  #     - CASSANDRA_USERNAME=cassandra
  #     - CASSANDRA_PASSWORD=cassandra
    # volumes:
    #   - ./:/home
